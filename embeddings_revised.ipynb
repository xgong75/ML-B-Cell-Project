{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "id": "0OilhQhq439-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import protein_utils as utils\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import ConcatDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZjJr1MA0OQVm",
    "outputId": "a79b473c-b717-41de-cfe9-05df93cde242",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12076, 14)\n"
     ]
    }
   ],
   "source": [
    "# file_path = \"input_bcell.csv\"\n",
    "# df=pd.read_csv(file_path)\n",
    "# print(df.shape)\n",
    "# df.iloc[:100,:].to_csv(\"input_bcell_truncated.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "id": "4DoN-z4s03OH",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ProteinDataset(Dataset):\n",
    "    #def __init__(self, sequences, peptides, start_positions, end_positions, labels, tokenizer, covariates, max_len=512):\n",
    "    def __init__(self, sequences, peptides, start_positions, end_positions, labels, tokenizer, max_len=512):\n",
    "        self.sequences = sequences\n",
    "        self.peptides = peptides\n",
    "        self.start_positions = start_positions\n",
    "        self.end_positions = end_positions\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        #self.covariates = torch.tensor(covariates, dtype=torch.float16)  # Convert covariates to tensor\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Tokenize parent sequence\n",
    "        parent_tokens = self.tokenizer(\n",
    "            self.sequences[idx],\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        # Tokenize peptide sequence\n",
    "        peptide_tokens = self.tokenizer(\n",
    "            self.peptides[idx],\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        # Extract covariates and labels\n",
    "        #covariates = self.covariates[idx]  # Access the covariates as tensors\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        return {\n",
    "            \"parent_tokens\": {key: val.squeeze(0) for key, val in parent_tokens.items()},\n",
    "            \"peptide_tokens\": {key: val.squeeze(0) for key, val in peptide_tokens.items()},\n",
    "            \"start_positions\": self.start_positions[idx],\n",
    "            \"end_positions\": self.end_positions[idx],\n",
    "            #\"covariates\": covariates,\n",
    "            \"labels\": label,\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fRe8HwhGpfE1"
   },
   "source": [
    "# Sequence Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qBjVy2Ha43-A",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read file\n",
    "file_path = \"input_bcell.csv\"\n",
    "\n",
    "# Split data\n",
    "df=pd.read_csv(file_path)\n",
    "covariates = df.iloc[:,5:-1].values\n",
    "parent_sequences = df.iloc[:,1].values\n",
    "start_positions = df.iloc[:,2].values\n",
    "end_positions = df.iloc[:,3].values\n",
    "peptide_sequences = df.iloc[:,4].values\n",
    "target = df[\"target\"].values\n",
    "\n",
    "# Add spaces and update indices\n",
    "parent_sequences = [\" \".join(seq) for seq in parent_sequences]\n",
    "peptide_sequences = [\" \".join(seq) for seq in peptide_sequences]\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_covariates = scaler.fit_transform(covariates)\n",
    "train_covariates, test_covariates, train_parent, test_parent, train_peptide, test_peptide, train_start, test_start, train_end, test_end, train_labels, test_labels = train_test_split(\n",
    "    scaled_covariates, parent_sequences, peptide_sequences, start_positions, end_positions, target, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"Rostlab/prot_bert\")\n",
    "\n",
    "# Align start and end positions for training and testing data\n",
    "aligned_train_start, aligned_train_end = utils.preprocess_data(train_parent, train_peptide, tokenizer)\n",
    "aligned_test_start, aligned_test_end = utils.preprocess_data(test_parent, test_peptide, tokenizer)\n",
    "\n",
    "# Replace raw start/end positions with aligned indices\n",
    "train_start = aligned_train_start\n",
    "train_end = aligned_train_end\n",
    "test_start = aligned_test_start\n",
    "test_end = aligned_test_end\n",
    "\n",
    "# Create DataLoaders\n",
    "# train_dataset = ProteinDataset(train_parent, train_peptide, train_start, train_end, train_labels, tokenizer, train_covariates)\n",
    "# test_dataset = ProteinDataset(test_parent, test_peptide, test_start, test_end, test_labels, tokenizer,test_covariates)\n",
    "train_dataset = ProteinDataset(train_parent, train_peptide, train_start, train_end, train_labels, tokenizer)\n",
    "test_dataset = ProteinDataset(test_parent, test_peptide, test_start, test_end, test_labels, tokenizer)\n",
    "\n",
    "all_dataset = ConcatDataset([train_dataset, test_dataset])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "all_loader = DataLoader(all_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "id": "BcmQ08-n43-D",
    "outputId": "087e30b9-a91d-444a-fa9b-e459b2d95f35",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Load ProtBERT model\\nmodel = BertModel.from_pretrained(\"Rostlab/prot_bert\")\\n\\n# Run each method\\npeptide_embeddings = utils.embed_peptide_only(model, peptide_tokens)\\nparent_embeddings = utils.extract_subsequence_embeddings(model, parent_tokens, start_positions, end_positions)\\nmasked_embeddings = utils.embed_with_masking(model, parent_tokens, start_positions, end_positions)\\nconcatenated_embeddings = utils.concatenate_embeddings(model, parent_tokens, peptide_tokens)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Load ProtBERT model\n",
    "model = BertModel.from_pretrained(\"Rostlab/prot_bert\")\n",
    "\n",
    "# Run each method\n",
    "peptide_embeddings = utils.embed_peptide_only(model, peptide_tokens)\n",
    "parent_embeddings = utils.extract_subsequence_embeddings(model, parent_tokens, start_positions, end_positions)\n",
    "masked_embeddings = utils.embed_with_masking(model, parent_tokens, start_positions, end_positions)\n",
    "concatenated_embeddings = utils.concatenate_embeddings(model, parent_tokens, peptide_tokens)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "-WbqtECC43-D",
    "outputId": "d727999d-1869-4162-e2a4-a651ab60feb6",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Save results\\nutils.save_embeddings(peptide_embeddings, \"results/peptide_embeddings.pt\")\\nutils.save_embeddings(parent_embeddings, \"results/parent_embeddings.pt\")\\nutils.save_embeddings(masked_embeddings, \"results/masked_embeddings.pt\")\\nutils.save_embeddings(concatenated_embeddings, \"results/concatenated_embeddings.pt\")\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Save results\n",
    "utils.save_embeddings(peptide_embeddings, \"results/peptide_embeddings.pt\")\n",
    "utils.save_embeddings(parent_embeddings, \"results/parent_embeddings.pt\")\n",
    "utils.save_embeddings(masked_embeddings, \"results/masked_embeddings.pt\")\n",
    "utils.save_embeddings(concatenated_embeddings, \"results/concatenated_embeddings.pt\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WCqpgdjeoTrY"
   },
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "id": "x3vCBmrj43-E",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BertAttentionClassifier(nn.Module):\n",
    "    #def __init__(self, bert_model_name=\"Rostlab/prot_bert\", hidden_dim=256, num_covariates=covariates.shape[1]):\n",
    "    def __init__(self, bert_model_name=\"Rostlab/prot_bert\", hidden_dim=256):\n",
    "        super(BertAttentionClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
    "\n",
    "        # Attention layer\n",
    "        self.attention = nn.Linear(1024, 1)\n",
    "\n",
    "        # Updated fully connected layer input size to include covariates\n",
    "        #print(num_covariates)\n",
    "        #self.fc1 = nn.Linear(1024 + num_covariates, hidden_dim)  # Combined input size\n",
    "        self.fc1 = nn.Linear(1024, hidden_dim)  # Combined input size\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim // 2)\n",
    "        self.fc3 = nn.Linear(hidden_dim // 2, 1)  # Output layer for binary classification\n",
    "\n",
    "    # def forward(self, mode, parent_tokens=None, peptide_tokens=None, start_positions=None,\n",
    "    #             end_positions=None, covariates=None):\n",
    "    #     # Embedding extraction based on the mode\n",
    "    #     if mode == \"peptide_only\":\n",
    "    #         embeddings = self.embed_peptide_only(peptide_tokens)\n",
    "    #         #print(f\"Shape of embeddings: {embeddings.shape}\")\n",
    "    #     elif mode == \"subsequence\":\n",
    "    #         embeddings = self.extract_subsequence_embeddings(parent_tokens, start_positions, end_positions)\n",
    "    #     elif mode == \"masked\":\n",
    "    #         embeddings = self.embed_with_masking(parent_tokens, start_positions, end_positions)\n",
    "    #     elif mode == \"concatenated\":\n",
    "    #         embeddings = self.concatenate_embeddings(parent_tokens, peptide_tokens)\n",
    "    #     elif mode == \"parent_only\":\n",
    "    #         embeddings = self.embed_parent_only(parent_tokens)\n",
    "    #     else:\n",
    "    #         raise ValueError(f\"Invalid embedding mode: {mode}\")\n",
    "\n",
    "    #     # Apply attention mechanism\n",
    "    #     attention_scores = self.attention(embeddings)   # Capture attention scores\n",
    "    #     embeddings = self.apply_attention(embeddings)  # Shape: [batch_size, 1024]\n",
    "\n",
    "    #     # Combine embedding with additional covariates\n",
    "    #     if covariates is not None:\n",
    "    #         covariates = covariates.to(\"cpu\")  # Keep covariates on CPU\n",
    "    #         combined_input = torch.cat([embeddings.to(\"cpu\"), covariates], dim=1).to(device)\n",
    "    #     else: #if no covariates, that means we only want the embeddings\n",
    "    #         return embeddings\n",
    "\n",
    "\n",
    "    def forward(self, mode, parent_tokens=None, peptide_tokens=None, start_positions=None, end_positions=None,final=0):\n",
    "        # Embedding extraction based on the mode\n",
    "        if mode == \"peptide_only\":\n",
    "            embeddings = self.embed_peptide_only(peptide_tokens)\n",
    "            #print(f\"Shape of embeddings: {embeddings.shape}\")\n",
    "        elif mode == \"subsequence\":\n",
    "            embeddings = self.extract_subsequence_embeddings(parent_tokens, start_positions, end_positions)\n",
    "        elif mode == \"masked\":\n",
    "            embeddings = self.embed_with_masking(parent_tokens, start_positions, end_positions)\n",
    "        elif mode == \"concatenated\":\n",
    "            embeddings = self.concatenate_embeddings(parent_tokens, peptide_tokens)\n",
    "        elif mode == \"parent_only\":\n",
    "            embeddings = self.embed_parent_only(parent_tokens)\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid embedding mode: {mode}\")\n",
    "\n",
    "        # Apply attention mechanism\n",
    "        attention_scores = self.attention(embeddings)   # Capture attention scores\n",
    "        embeddings = self.apply_attention(embeddings)  # Shape: [batch_size, 1024]\n",
    "\n",
    "        combined_input = embeddings\n",
    "        if final==1: # if it's final extraction mode, we return directly after attention layer\n",
    "            return combined_input\n",
    "\n",
    "        # Classification layers\n",
    "        x = F.relu(self.fc1(combined_input))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x, attention_scores\n",
    "\n",
    "    def apply_attention(self, embeddings):\n",
    "        \"\"\"Apply attention mechanism to the embeddings.\"\"\"\n",
    "        #print(f\"Input embeddings shape before attention: {embeddings.shape}\")\n",
    "        # Debugging: Ensure embeddings have the expected shape [batch_size, seq_length, 1024]\n",
    "\n",
    "        scores = self.attention(embeddings)  # Linear layer to calculate attention scores\n",
    "        #print(f\"Attention scores shape after self.attention: {scores.shape}\")\n",
    "        # Debugging: Should be [batch_size, seq_length, 1]\n",
    "\n",
    "        scores = torch.softmax(scores, dim=1)  # Normalize scores across seq_length\n",
    "        #print(f\"Attention scores shape after softmax: {scores.shape}\")\n",
    "        # Debugging: Should remain [batch_size, seq_length, 1]\n",
    "\n",
    "        # Element-wise multiplication and summation to compute attended embeddings\n",
    "        attended_embeddings = torch.sum(scores * embeddings, dim=1)\n",
    "        #print(f\"Output attended embeddings shape: {attended_embeddings.shape}\")\n",
    "        # Debugging: Should be [batch_size, 1024]\n",
    "\n",
    "        return attended_embeddings\n",
    "\n",
    "    def embed_parent_only(self, parent_tokens):\n",
    "        \"\"\"Baseline: Disregard peptide subsequence and only evaluate on full information\"\"\"\n",
    "        outputs = self.bert(**parent_tokens)\n",
    "        embeddings = outputs.last_hidden_state\n",
    "        return embeddings\n",
    "\n",
    "    def embed_peptide_only(self, peptide_tokens):\n",
    "        \"\"\"Generate embeddings for the peptide subsequence only.\"\"\"\n",
    "        outputs = self.bert(**peptide_tokens)\n",
    "        embeddings = outputs.last_hidden_state\n",
    "        return embeddings\n",
    "\n",
    "    # Embed parent and extract peptide subsequence\n",
    "    def extract_subsequence_embeddings(self, parent_tokens, start_positions, end_positions):\n",
    "        \"\"\"\n",
    "        Extract embeddings for subsequences within parent sequences.\n",
    "        Args:\n",
    "            parent_tokens: Tokenized parent sequences.\n",
    "            start_positions: Aligned start positions for subsequences.\n",
    "            end_positions: Aligned end positions for subsequences.\n",
    "        Returns:\n",
    "            subsequence_embeddings: Tensor of subsequence embeddings.\n",
    "        \"\"\"\n",
    "        outputs = self.bert(**parent_tokens)\n",
    "        parent_embeddings = outputs.last_hidden_state  # Shape: [batch_size, seq_length, hidden_dim]\n",
    "\n",
    "        subsequence_embeddings = []\n",
    "        for i, (start, end) in enumerate(zip(start_positions, end_positions)):\n",
    "            seq_length = parent_embeddings.size(1)  # Tokenized sequence length\n",
    "\n",
    "            # Validate indices\n",
    "            if 0 <= start < seq_length and 0 <= end < seq_length and start <= end:\n",
    "                subsequence = parent_embeddings[i, start:end + 1, :]  # Extract subsequence\n",
    "                subsequence_embeddings.append(subsequence)\n",
    "            else:\n",
    "                print(f\"Invalid indices for sample {i}: start={start}, end={end}, seq_length={seq_length}\")\n",
    "                raise ValueError(\"Invalid start or end position\")\n",
    "\n",
    "        # Pad subsequences to ensure uniform length (optional)\n",
    "        max_length = max([sub.size(0) for sub in subsequence_embeddings])\n",
    "        padded_embeddings = [\n",
    "            F.pad(sub, (0, 0, 0, max_length - sub.size(0))) for sub in subsequence_embeddings\n",
    "        ]\n",
    "        subsequence_embeddings = torch.stack(padded_embeddings, dim=0)  # Shape: [batch_size, max_length, hidden_dim]\n",
    "\n",
    "        return subsequence_embeddings\n",
    "\n",
    "    def embed_with_masking(self, parent_tokens, start_positions, end_positions):\n",
    "        \"\"\"Generate embeddings with non-peptide regions masked.\"\"\"\n",
    "        input_ids, attention_mask = utils.mask_non_peptide_regions(\n",
    "            parent_tokens['input_ids'], parent_tokens['attention_mask'], start_positions, end_positions\n",
    "        )\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        embeddings = outputs.last_hidden_state\n",
    "        return embeddings\n",
    "\n",
    "    # Embed parent and peptide separately and concatenate\n",
    "    def concatenate_embeddings(self, parent_tokens, peptide_tokens):\n",
    "        \"\"\"Generate and concatenate parent and peptide embeddings.\"\"\"\n",
    "        parent_outputs = self.bert(**parent_tokens)\n",
    "        peptide_outputs = self.bert(**peptide_tokens)\n",
    "\n",
    "        # Extract the last hidden state\n",
    "        parent_embeddings = parent_outputs.last_hidden_state  # Shape: [batch_size, parent_seq_len, hidden_dim]\n",
    "        peptide_embeddings = peptide_outputs.last_hidden_state\n",
    "\n",
    "        concatenated_embeddings = torch.cat((parent_embeddings, peptide_embeddings), dim=1)  # Combine\n",
    "        return concatenated_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "id": "_s9_hlvq43-G",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train_model(model, dataloader, criterion, optimizer, mode, num_epochs=10):\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        # Add a progress bar for the batches\n",
    "        progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\", leave=True)\n",
    "\n",
    "        for batch in progress_bar:\n",
    "        #for batch in dataloader:\n",
    "            # Move data to device\n",
    "            parent_tokens = {k: v.to(device) for k, v in batch[\"parent_tokens\"].items()}\n",
    "            peptide_tokens = {k: v.to(device) for k, v in batch[\"peptide_tokens\"].items()}\n",
    "            start_positions = batch[\"start_positions\"]\n",
    "            end_positions = batch[\"end_positions\"]\n",
    "            #covariates = batch[\"covariates\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            # Forward pass with the chosen embedding method\n",
    "            logits, attention_scores = model(\n",
    "                mode=mode,\n",
    "                parent_tokens=parent_tokens,\n",
    "                peptide_tokens=peptide_tokens,\n",
    "                start_positions=start_positions,\n",
    "                end_positions=end_positions,\n",
    "                #covariates=covariates\n",
    "                final=0\n",
    "            )\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(logits.squeeze(), labels.float())\n",
    "\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Update progress bar\n",
    "            progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "id": "C_7uGrjTrKGI",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, loader, device,mode):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    total_loss = 0\n",
    "    mode=mode\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    progress_bar = tqdm(loader, desc=\"Evaluating\", unit=\"batch\", leave=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in progress_bar:\n",
    "            # Move data to device\n",
    "            parent_tokens = {k: v.to(device) for k, v in batch[\"parent_tokens\"].items()}\n",
    "            peptide_tokens = {k: v.to(device) for k, v in batch[\"peptide_tokens\"].items()}\n",
    "            start_positions = batch[\"start_positions\"]\n",
    "            end_positions = batch[\"end_positions\"]\n",
    "            #covariates = batch[\"covariates\"].to(device)  # Ensure covariates are on the same device\n",
    "            #print(covariates.size())\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            logits, _ = model(\n",
    "                mode=mode,\n",
    "                parent_tokens=parent_tokens,\n",
    "                peptide_tokens=peptide_tokens,\n",
    "                start_positions=start_positions,\n",
    "                end_positions=end_positions,\n",
    "                #covariates=covariates\n",
    "                final=0\n",
    "            )\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(logits.squeeze(), labels.float())\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Convert logits to probabilities\n",
    "            probabilities = torch.sigmoid(logits).squeeze()\n",
    "            predictions = (probabilities > 0.5).float()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            correct += (predictions == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    avg_loss = total_loss / len(loader)\n",
    "\n",
    "    print(f\"Evaluation Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def extract_final_embeddings(model, dataloader, mode, device):\n",
    "    \"\"\"\n",
    "    Extract embeddings from the model after the attention layer.\n",
    "\n",
    "    Args:\n",
    "        model: The trained model instance.\n",
    "        dataloader: DataLoader containing the dataset.\n",
    "        mode: The embedding mode (\"peptide_only\", \"subsequence\", etc.).\n",
    "        device: The device to run the model on (\"cpu\" or \"cuda\").\n",
    "\n",
    "    Returns:\n",
    "        final_embeddings: Tensor containing all extracted embeddings.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    final_embeddings = []\n",
    "\n",
    "    # Progress bar for monitoring the extraction process\n",
    "    progress_bar = tqdm(dataloader, desc=\"Extracting Final Embeddings\", unit=\"batch\", leave=True)\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation for inference\n",
    "        for batch in progress_bar:\n",
    "            # Move data to the appropriate device\n",
    "            parent_tokens = {k: v.to(device) for k, v in batch[\"parent_tokens\"].items()}\n",
    "            peptide_tokens = {k: v.to(device) for k, v in batch[\"peptide_tokens\"].items()}\n",
    "            start_positions = batch[\"start_positions\"]\n",
    "            end_positions = batch[\"end_positions\"]\n",
    "\n",
    "            # Get embeddings after attention\n",
    "            embeddings = model(\n",
    "                mode=mode,\n",
    "                parent_tokens=parent_tokens,\n",
    "                peptide_tokens=peptide_tokens,\n",
    "                start_positions=start_positions,\n",
    "                end_positions=end_positions,\n",
    "                #covariates=None  # Exclude covariates to get embeddings directly\n",
    "                final=1\n",
    "            )\n",
    "            # Move embeddings to CPU and store\n",
    "            final_embeddings.append(embeddings)\n",
    "\n",
    "    # Combine all embeddings into a single tensor\n",
    "    # final_embeddings = torch.cat(final_embeddings, dim=0)\n",
    "    return final_embeddings\n",
    "\n",
    "def save_embeddings(method,embeddings):\n",
    "  output_dir = \"results\"\n",
    "  os.makedirs(output_dir, exist_ok=True)  # Ensure directory exists\n",
    "  file_path = f\"{output_dir}/{method}_final_embeddings.pt\"\n",
    "  torch.save(embeddings, file_path)\n",
    "  print(f\"Saved final embeddings for {method} to {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dn6nDK85rFvT"
   },
   "source": [
    "## Parent Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kuto4XUJ43-H",
    "outputId": "f3015cc5-6430-4a5b-aa43-288e4c3fcd0b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating for embedding method: parent_only\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 5/5 [00:08<00:00,  1.67s/batch, loss=0.299]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 1.2918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 5/5 [00:08<00:00,  1.66s/batch, loss=0.155]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5, Loss: 1.1035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 5/5 [00:08<00:00,  1.66s/batch, loss=0.108]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5, Loss: 0.7085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 5/5 [00:08<00:00,  1.66s/batch, loss=0.0899]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5, Loss: 0.2796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 5/5 [00:08<00:00,  1.66s/batch, loss=0.6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5, Loss: 0.8969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the embedding methods to loop through\n",
    "embedding_methods = \"parent_only\"\n",
    "#embedding_methods = [\"parent_only\",\"peptide_only\", \"subsequence\", \"masked\", \"concatenated\"]\n",
    "\n",
    "# Parameters\n",
    "num_epochs = 5\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Dataset is imbalanced (train set is 27% positive) so weighting loss function\n",
    "# Calculate class weights\n",
    "num_positives = sum(train_labels)  # Number of positive samples in the training set\n",
    "num_negatives = len(train_labels) - num_positives  # Number of negative samples\n",
    "pos_weight = num_negatives / num_positives  # Positive class weight\n",
    "pos_weight_tensor = torch.tensor(pos_weight).to(device)  # Ensure compatibility with GPU\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight_tensor)\n",
    "\n",
    "# Store results for accuracy and embeddings\n",
    "results = {}\n",
    "final_embeddings = {}\n",
    "\n",
    "print(f\"Training and evaluating for embedding method: {embedding_methods}\")\n",
    "\n",
    "# Initialize the model for each method\n",
    "model = BertAttentionClassifier(bert_model_name=\"Rostlab/prot_bert\", hidden_dim=256)\n",
    "model.bert.gradient_checkpointing_enable()\n",
    "\n",
    "# Move to device (GPU or CPU)\n",
    "model.to(device)\n",
    "\n",
    "# Define optimizer for each run\n",
    "optimizer = torch.optim.AdamW(\n",
    "    [\n",
    "        {'params': model.bert.parameters(), 'lr': 1e-4},  # Fine-tuning BERT with a smaller learning rate\n",
    "        {'params': model.fc1.parameters(), 'lr': 1e-3},  # Classifier hidden layer\n",
    "        {'params': model.fc2.parameters(), 'lr': 1e-3},  # Classifier hidden layer\n",
    "        {'params': model.fc3.parameters(), 'lr': 1e-3},  # Classifier output layer\n",
    "        {'params': model.attention.parameters(), 'lr': 1e-3},  # Attention layer\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Train the model for the current embedding method\n",
    "train_model(\n",
    "    model=model,\n",
    "    dataloader=train_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    mode=embedding_methods,\n",
    "    num_epochs=num_epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FXUjr6_miKfS",
    "outputId": "b62c4af4-fc56-42be-aafa-8cd5cbeaa2ef",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00,  3.43batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Accuracy: 45.00%\n",
      "Average Loss: 2.5571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Final Embeddings: 100%|██████████| 7/7 [00:02<00:00,  2.88batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved final embeddings for parent_only to results/parent_only_final_embeddings.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy=evaluate_model(model, test_loader, device, embedding_methods)\n",
    "final_embeddings=extract_final_embeddings(model, all_loader, embedding_methods,device=device)\n",
    "#final_embeddings.shape\n",
    "save_embeddings(embedding_methods,final_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KewoDsfKrbmD"
   },
   "source": [
    "## Peptide Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6jOZWdfSrbmD",
    "outputId": "7442d72d-81ff-432e-cdbf-0b6417b1e53b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating for embedding method: peptide_only\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 5/5 [00:08<00:00,  1.67s/batch, loss=0.195]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 1.3107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|██████████| 5/5 [00:08<00:00,  1.66s/batch, loss=0.197]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 1.3058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|██████████| 5/5 [00:08<00:00,  1.66s/batch, loss=0.225]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 1.3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00,  3.45batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Accuracy: 85.00%\n",
      "Average Loss: 0.6816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Final Embeddings: 100%|██████████| 7/7 [00:02<00:00,  2.88batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved final embeddings for peptide_only to results/peptide_only_final_embeddings.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the embedding methods to loop through\n",
    "embedding_methods = \"peptide_only\"\n",
    "#embedding_methods = [\"parent_only\",\"peptide_only\", \"subsequence\", \"masked\", \"concatenated\"]\n",
    "\n",
    "# Parameters\n",
    "num_epochs = 5\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Dataset is imbalanced (train set is 27% positive) so weighting loss function\n",
    "# Calculate class weights\n",
    "num_positives = sum(train_labels)  # Number of positive samples in the training set\n",
    "num_negatives = len(train_labels) - num_positives  # Number of negative samples\n",
    "pos_weight = num_negatives / num_positives  # Positive class weight\n",
    "pos_weight_tensor = torch.tensor(pos_weight).to(device)  # Ensure compatibility with GPU\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight_tensor)\n",
    "\n",
    "# Store results for accuracy and embeddings\n",
    "results = {}\n",
    "final_embeddings = {}\n",
    "\n",
    "print(f\"Training and evaluating for embedding method: {embedding_methods}\")\n",
    "\n",
    "# Initialize the model for each method\n",
    "model = BertAttentionClassifier(bert_model_name=\"Rostlab/prot_bert\", hidden_dim=256)\n",
    "model.bert.gradient_checkpointing_enable()\n",
    "\n",
    "# Move to device (GPU or CPU)\n",
    "model.to(device)\n",
    "\n",
    "# Define optimizer for each run\n",
    "optimizer = torch.optim.AdamW(\n",
    "    [\n",
    "        {'params': model.bert.parameters(), 'lr': 1e-4},  # Fine-tuning BERT with a smaller learning rate\n",
    "        {'params': model.fc1.parameters(), 'lr': 1e-3},  # Classifier hidden layer\n",
    "        {'params': model.fc2.parameters(), 'lr': 1e-3},  # Classifier hidden layer\n",
    "        {'params': model.fc3.parameters(), 'lr': 1e-3},  # Classifier output layer\n",
    "        {'params': model.attention.parameters(), 'lr': 1e-3},  # Attention layer\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Train the model for the current embedding method\n",
    "train_model(\n",
    "    model=model,\n",
    "    dataloader=train_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    mode=embedding_methods,\n",
    "    num_epochs=num_epochs\n",
    ")\n",
    "accuracy=evaluate_model(model, test_loader, device,embedding_methods)\n",
    "final_embeddings=extract_final_embeddings(model, all_loader, embedding_methods,device=device)\n",
    "save_embeddings(embedding_methods,final_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SRV8yONmr96V",
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2w-szPMfwGeY"
   },
   "source": [
    "## subsequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Uqiy_c2wHfy",
    "outputId": "38087a9c-199a-4037-8374-ca50cb59441a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating for embedding method: subsequence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 5/5 [00:08<00:00,  1.68s/batch, loss=0.293]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 1.3024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|██████████| 5/5 [00:08<00:00,  1.67s/batch, loss=0.208]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 1.1029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|██████████| 5/5 [00:08<00:00,  1.67s/batch, loss=0.234]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.8477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rEvaluating:   0%|          | 0/2 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00,  3.42batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8])\n",
      "Evaluation Accuracy: 100.00%\n",
      "Average Loss: 0.1587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Final Embeddings: 100%|██████████| 7/7 [00:02<00:00,  2.88batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved final embeddings for subsequence to results/subsequence_final_embeddings.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the embedding methods to loop through\n",
    "embedding_methods = \"subsequence\"\n",
    "#embedding_methods = [\"parent_only\",\"peptide_only\", \"subsequence\", \"masked\", \"concatenated\"]\n",
    "\n",
    "# Parameters\n",
    "num_epochs = 5\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Dataset is imbalanced (train set is 27% positive) so weighting loss function\n",
    "# Calculate class weights\n",
    "num_positives = sum(train_labels)  # Number of positive samples in the training set\n",
    "num_negatives = len(train_labels) - num_positives  # Number of negative samples\n",
    "pos_weight = num_negatives / num_positives  # Positive class weight\n",
    "pos_weight_tensor = torch.tensor(pos_weight).to(device)  # Ensure compatibility with GPU\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight_tensor)\n",
    "\n",
    "# Store results for accuracy and embeddings\n",
    "results = {}\n",
    "final_embeddings = {}\n",
    "\n",
    "print(f\"Training and evaluating for embedding method: {embedding_methods}\")\n",
    "\n",
    "# Initialize the model for each method\n",
    "model = BertAttentionClassifier(bert_model_name=\"Rostlab/prot_bert\", hidden_dim=256)\n",
    "model.bert.gradient_checkpointing_enable()\n",
    "\n",
    "# Move to device (GPU or CPU)\n",
    "model.to(device)\n",
    "\n",
    "# Define optimizer for each run\n",
    "optimizer = torch.optim.AdamW(\n",
    "    [\n",
    "        {'params': model.bert.parameters(), 'lr': 1e-4},  # Fine-tuning BERT with a smaller learning rate\n",
    "        {'params': model.fc1.parameters(), 'lr': 1e-3},  # Classifier hidden layer\n",
    "        {'params': model.fc2.parameters(), 'lr': 1e-3},  # Classifier hidden layer\n",
    "        {'params': model.fc3.parameters(), 'lr': 1e-3},  # Classifier output layer\n",
    "        {'params': model.attention.parameters(), 'lr': 1e-3},  # Attention layer\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Train the model for the current embedding method\n",
    "train_model(\n",
    "    model=model,\n",
    "    dataloader=train_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    mode=embedding_methods,\n",
    "    num_epochs=num_epochs\n",
    ")\n",
    "\n",
    "accuracy=evaluate_model(model, test_loader, device,embedding_methods)\n",
    "final_embeddings=extract_final_embeddings(model, all_loader, embedding_methods,device=device)\n",
    "save_embeddings(embedding_methods,final_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WyxEyZTbmAgp",
    "outputId": "a63f4fec-fd48-46d1-cd54-0096775f6cdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0         1         2         3         4         5         6     \\\n",
      "0 -0.114157  0.248824  0.014217  0.050114  0.033292  0.016470 -0.013134   \n",
      "1 -0.132596  0.253248 -0.082209  0.010419 -0.213525 -0.148483 -0.004346   \n",
      "2 -0.170352  0.158309 -0.027124 -0.024673 -0.101800 -0.043206 -0.090205   \n",
      "3 -0.076508  0.096773 -0.033277 -0.095106 -0.208793 -0.155706 -0.049120   \n",
      "4 -0.081266  0.081046  0.020499 -0.128383 -0.179900 -0.045796  0.034417   \n",
      "\n",
      "       7         8         9     ...      1014      1015      1016      1017  \\\n",
      "0 -0.030876 -0.062250  0.062992  ...  0.001058  0.091619  0.058876 -0.077734   \n",
      "1 -0.167261 -0.102770 -0.051028  ... -0.172340  0.029804  0.058265 -0.241839   \n",
      "2 -0.281302 -0.110784 -0.011791  ... -0.164307  0.093185  0.027939 -0.152268   \n",
      "3 -0.163977 -0.108256  0.040491  ... -0.356882  0.155240  0.069389 -0.088114   \n",
      "4 -0.242266 -0.036848 -0.001851  ... -0.283149  0.064167  0.102296 -0.104585   \n",
      "\n",
      "       1018      1019      1020      1021      1022      1023  \n",
      "0  0.003833 -0.024557  0.126980  0.014466 -0.040965  0.113288  \n",
      "1 -0.013282 -0.023085  0.078686  0.075898  0.006044  0.089252  \n",
      "2  0.031281 -0.086885  0.112341 -0.001598 -0.091613  0.044958  \n",
      "3  0.138762 -0.044002  0.167230  0.057179 -0.036107  0.097478  \n",
      "4  0.043573 -0.179836  0.100364  0.069007 -0.060592 -0.024032  \n",
      "\n",
      "[5 rows x 1024 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-28-78385d73ad7e>:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  embeddings = torch.load(file_path)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# Load the saved embeddings\n",
    "method = 'subsequence'  # Replace with the method used when saving the embeddings\n",
    "file_path = f\"results/{method}_final_embeddings.pt\"\n",
    "\n",
    "# Load the embeddings from the .pt file\n",
    "embeddings = torch.load(file_path)\n",
    "\n",
    "# If embeddings are a tensor, convert to a DataFrame\n",
    "if isinstance(embeddings, torch.Tensor):\n",
    "    # Move the tensor to CPU and convert to numpy\n",
    "    embeddings_cpu = embeddings.cpu().numpy()  # Use .cpu() before .numpy()\n",
    "    df = pd.DataFrame(embeddings_cpu)  # Convert the numpy array to a DataFrame\n",
    "elif isinstance(embeddings, dict):  # If embeddings are stored as a dictionary\n",
    "    # If the embeddings are stored as a dictionary, you can extract the values and convert\n",
    "    df = pd.DataFrame(embeddings)  # Example: If embeddings are already in a suitable format\n",
    "else:\n",
    "    print(\"Unsupported embeddings format\")\n",
    "\n",
    "# Check the first few rows of the DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1PxmfENoDPjg"
   },
   "source": [
    "## masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BwbptFCSDPjg",
    "outputId": "86ba5d91-afb5-429c-8b36-78c08b00eedf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating for embedding method: masked\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 5/5 [00:08<00:00,  1.67s/batch, loss=0.259]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 1.2987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|██████████| 5/5 [00:08<00:00,  1.67s/batch, loss=0.219]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 1.2901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|██████████| 5/5 [00:08<00:00,  1.67s/batch, loss=0.336]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 1.2841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rEvaluating:   0%|          | 0/2 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00,  3.42batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8])\n",
      "Evaluation Accuracy: 85.00%\n",
      "Average Loss: 0.6378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Final Embeddings: 100%|██████████| 7/7 [00:02<00:00,  2.88batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved final embeddings for masked to results/masked_final_embeddings.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the embedding methods to loop through\n",
    "embedding_methods = \"masked\"\n",
    "#embedding_methods = [\"parent_only\",\"peptide_only\", \"subsequence\", \"masked\", \"concatenated\"]\n",
    "\n",
    "# Parameters\n",
    "num_epochs = 5\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Dataset is imbalanced (train set is 27% positive) so weighting loss function\n",
    "# Calculate class weights\n",
    "num_positives = sum(train_labels)  # Number of positive samples in the training set\n",
    "num_negatives = len(train_labels) - num_positives  # Number of negative samples\n",
    "pos_weight = num_negatives / num_positives  # Positive class weight\n",
    "pos_weight_tensor = torch.tensor(pos_weight).to(device)  # Ensure compatibility with GPU\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight_tensor)\n",
    "\n",
    "# Store results for accuracy and embeddings\n",
    "results = {}\n",
    "final_embeddings = {}\n",
    "\n",
    "print(f\"Training and evaluating for embedding method: {embedding_methods}\")\n",
    "\n",
    "# Initialize the model for each method\n",
    "model = BertAttentionClassifier(bert_model_name=\"Rostlab/prot_bert\", hidden_dim=256)\n",
    "model.bert.gradient_checkpointing_enable()\n",
    "\n",
    "# Move to device (GPU or CPU)\n",
    "model.to(device)\n",
    "\n",
    "# Define optimizer for each run\n",
    "optimizer = torch.optim.AdamW(\n",
    "    [\n",
    "        {'params': model.bert.parameters(), 'lr': 1e-4},  # Fine-tuning BERT with a smaller learning rate\n",
    "        {'params': model.fc1.parameters(), 'lr': 1e-3},  # Classifier hidden layer\n",
    "        {'params': model.fc2.parameters(), 'lr': 1e-3},  # Classifier hidden layer\n",
    "        {'params': model.fc3.parameters(), 'lr': 1e-3},  # Classifier output layer\n",
    "        {'params': model.attention.parameters(), 'lr': 1e-3},  # Attention layer\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Train the model for the current embedding method\n",
    "train_model(\n",
    "    model=model,\n",
    "    dataloader=train_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    mode=embedding_methods,\n",
    "    num_epochs=num_epochs\n",
    ")\n",
    "\n",
    "accuracy=evaluate_model(model, test_loader, device,embedding_methods)\n",
    "final_embeddings=extract_final_embeddings(model, all_loader, embedding_methods,device=device)\n",
    "save_embeddings(embedding_methods,final_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G8E6QU3-CnzM",
    "outputId": "4f91811d-7502-49d1-cd0c-4f7cdb227ee3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0446,  0.0432, -0.1188,  ..., -0.0144,  0.0302,  0.0203],\n",
       "        [-0.0447,  0.0429, -0.1186,  ..., -0.0147,  0.0304,  0.0204],\n",
       "        [-0.0447,  0.0430, -0.1186,  ..., -0.0146,  0.0304,  0.0204],\n",
       "        ...,\n",
       "        [-0.0446,  0.0432, -0.1188,  ..., -0.0143,  0.0300,  0.0203],\n",
       "        [-0.0446,  0.0431, -0.1188,  ..., -0.0143,  0.0302,  0.0203],\n",
       "        [-0.0449,  0.0431, -0.1184,  ..., -0.0148,  0.0303,  0.0205]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xPrSa8FSDPjg"
   },
   "source": [
    "## concatenated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FUuX__73DPjg"
   },
   "outputs": [],
   "source": [
    "# Define the embedding methods to loop through\n",
    "embedding_methods = \"concatenated\"\n",
    "#embedding_methods = [\"parent_only\",\"peptide_only\", \"subsequence\", \"masked\", \"concatenated\"]\n",
    "\n",
    "# Parameters\n",
    "num_epochs = 5\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Dataset is imbalanced (train set is 27% positive) so weighting loss function\n",
    "# Calculate class weights\n",
    "num_positives = sum(train_labels)  # Number of positive samples in the training set\n",
    "num_negatives = len(train_labels) - num_positives  # Number of negative samples\n",
    "pos_weight = num_negatives / num_positives  # Positive class weight\n",
    "pos_weight_tensor = torch.tensor(pos_weight).to(device)  # Ensure compatibility with GPU\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight_tensor)\n",
    "\n",
    "# Store results for accuracy and embeddings\n",
    "results = {}\n",
    "final_embeddings = {}\n",
    "\n",
    "print(f\"Training and evaluating for embedding method: {embedding_methods}\")\n",
    "\n",
    "# Initialize the model for each method\n",
    "model = BertAttentionClassifier(bert_model_name=\"Rostlab/prot_bert\", hidden_dim=256)\n",
    "model.bert.gradient_checkpointing_enable()\n",
    "\n",
    "# Move to device (GPU or CPU)\n",
    "model.to(device)\n",
    "\n",
    "# Define optimizer for each run\n",
    "optimizer = torch.optim.AdamW(\n",
    "    [\n",
    "        {'params': model.bert.parameters(), 'lr': 1e-4},  # Fine-tuning BERT with a smaller learning rate\n",
    "        {'params': model.fc1.parameters(), 'lr': 1e-3},  # Classifier hidden layer\n",
    "        {'params': model.fc2.parameters(), 'lr': 1e-3},  # Classifier hidden layer\n",
    "        {'params': model.fc3.parameters(), 'lr': 1e-3},  # Classifier output layer\n",
    "        {'params': model.attention.parameters(), 'lr': 1e-3},  # Attention layer\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Train the model for the current embedding method\n",
    "train_model(\n",
    "    model=model,\n",
    "    dataloader=train_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    mode=embedding_methods,\n",
    "    num_epochs=num_epochs\n",
    ")\n",
    "\n",
    "accuracy=evaluate_model(model, test_loader, device,embedding_methods)\n",
    "final_embeddings=extract_final_embeddings(model, all_loader, embedding_methods,device=device)\n",
    "save_embeddings(embedding_methods,final_embeddings)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
